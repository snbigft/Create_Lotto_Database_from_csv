{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGLXVoGZwZeiJF6RlDb+6h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snbigft/Create_Lotto_Database_from_csv/blob/main/Inserta_datos_Lotto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3tSi04r0wKx",
        "outputId": "84ee6b18-3d5b-4896-92e6-4556abc63985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archivo CSV cargado con éxito. Número de filas: 101373\n",
            "Conexión a la base de datos establecida correctamente.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit realizado después de insertar 10000 filas.\n",
            "Commit final realizado con 6865 filas restantes.\n",
            "Datos insertados correctamente en la tabla LOTTO_IT.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import psycopg2\n",
        "from psycopg2 import sql , extras\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "# Configuración de la base de datos\n",
        "DB_HOST = \"ep-snowy-dawn-a8omlpke-pooler.eastus2.azure.neon.tech\"\n",
        "DB_NAME = \"neondb\"\n",
        "DB_USER = \"neondb_owner\"\n",
        "DB_PASSWORD = \"npg_BcpnId62FYhS\"\n",
        "\n",
        "# Configuración de inserción en bloques\n",
        "chunk = 10000  # Número de filas en la BBDD antes de cada commit\n",
        "filas_por_linea_csv = 5  # Cada línea del CSV inserta 5 filas en la BBDD\n",
        "lineas_por_chunk = chunk // filas_por_linea_csv  # Número de líneas del CSV por cada commit\n",
        "\n",
        "def get_db_connection():\n",
        "    return psycopg2.connect(\n",
        "        host=DB_HOST,\n",
        "        dbname=DB_NAME,\n",
        "        user=DB_USER,\n",
        "        password=DB_PASSWORD,\n",
        "        sslmode=\"require\"\n",
        "    )\n",
        "\n",
        "# Montar Google Drive y leer el fichero CSV\n",
        "drive.mount('/content/drive')\n",
        "csv_file_path = '/content/drive/My Drive/Lotto_it.csv'\n",
        "\n",
        "# Leer el CSV con manejo de errores\n",
        "try:\n",
        "    df = pd.read_csv(csv_file_path, sep=';', encoding='ISO-8859-1')\n",
        "    print(f\"Archivo CSV cargado con éxito. Número de filas: {len(df)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al leer el archivo CSV: {e}\")\n",
        "\n",
        "# Conectar a la base de datos\n",
        "try:\n",
        "    conn = get_db_connection()\n",
        "    cursor = conn.cursor()\n",
        "    print(\"Conexión a la base de datos establecida correctamente.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al conectar a la base de datos: {e}\")\n",
        "\n",
        "# Almacenar las consultas antes de ejecutarlas en bloque\n",
        "insert_values = []\n",
        "\n",
        "# Recorrer cada fila del CSV\n",
        "for index, row in df.iterrows():\n",
        "    try:\n",
        "        data = row['Data estr.']\n",
        "        ordine = int(row['ordine'])\n",
        "        ruota = row['Ruota']\n",
        "        numeros = [row['1°'], row['2°'], row['3°'], row['4°'], row['5°']]\n",
        "\n",
        "        # Preparar cinco filas para insertar en la tabla LOTTO_IT\n",
        "        for posicion, numero in enumerate(numeros, start=1):\n",
        "            json_data = json.dumps({\n",
        "                \"data\": data,\n",
        "                \"ordine\": str(ordine),\n",
        "                \"ruota\": ruota,\n",
        "                \"posicion\": str(posicion),\n",
        "                \"numero\": str(numero)\n",
        "            })\n",
        "\n",
        "            # Almacenar los valores en la lista para la inserción en bloque\n",
        "            insert_values.append((data, ordine, ruota, int(numero), json_data, posicion))\n",
        "\n",
        "        # Realizar la inserción en bloque cada 'chunk' filas\n",
        "        if len(insert_values) >= chunk:\n",
        "            insert_query = sql.SQL(\"\"\"\n",
        "                INSERT INTO \"lotto_it\" (giorno, ordine, ruota, numero, json_data, posicion)\n",
        "                VALUES %s\n",
        "            \"\"\")\n",
        "\n",
        "            psycopg2.extras.execute_values(\n",
        "                cursor, insert_query.as_string(conn), insert_values, template=None, page_size=100\n",
        "            )\n",
        "\n",
        "            conn.commit()\n",
        "            print(f\"Commit realizado después de insertar {len(insert_values)} filas.\")\n",
        "            insert_values = []\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error procesando la fila {index+1}: {e}\")\n",
        "\n",
        "# Insertar cualquier fila restante que no alcanzó el chunk completo\n",
        "if insert_values:\n",
        "    insert_query = sql.SQL(\"\"\"\n",
        "        INSERT INTO \"lotto_it\" (giorno, ordine, ruota, numero, json_data, posicion)\n",
        "        VALUES %s\n",
        "    \"\"\")\n",
        "\n",
        "    psycopg2.extras.execute_values(\n",
        "        cursor, insert_query.as_string(conn), insert_values, template=None, page_size=100\n",
        "    )\n",
        "\n",
        "    conn.commit()\n",
        "    print(f\"Commit final realizado con {len(insert_values)} filas restantes.\")\n",
        "\n",
        "# Cerrar conexión\n",
        "cursor.close()\n",
        "conn.close()\n",
        "print(\"Datos insertados correctamente en la tabla LOTTO_IT.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BIY-NsGf1_EO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}